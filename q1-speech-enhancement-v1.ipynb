{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":11210813,"sourceType":"datasetVersion","datasetId":7000298}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!python --version","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-30T14:42:41.283344Z","iopub.execute_input":"2025-03-30T14:42:41.283692Z","iopub.status.idle":"2025-03-30T14:42:41.407430Z","shell.execute_reply.started":"2025-03-30T14:42:41.283663Z","shell.execute_reply":"2025-03-30T14:42:41.406688Z"}},"outputs":[{"name":"stdout","text":"Python 3.10.12\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"!pip install torchaudio transformers speechbrain torchmetrics pesq pystoi loralib","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-30T14:42:45.108870Z","iopub.execute_input":"2025-03-30T14:42:45.109177Z","iopub.status.idle":"2025-03-30T14:42:59.193692Z","shell.execute_reply.started":"2025-03-30T14:42:45.109155Z","shell.execute_reply":"2025-03-30T14:42:59.192704Z"},"_kg_hide-input":false},"outputs":[{"name":"stdout","text":"Requirement already satisfied: torchaudio in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\nRequirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.47.0)\nCollecting speechbrain\n  Downloading speechbrain-1.0.2-py3-none-any.whl.metadata (23 kB)\nRequirement already satisfied: torchmetrics in /usr/local/lib/python3.10/dist-packages (1.6.1)\nCollecting pesq\n  Downloading pesq-0.0.4.tar.gz (38 kB)\n  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nCollecting pystoi\n  Downloading pystoi-0.4.1-py2.py3-none-any.whl.metadata (4.0 kB)\nCollecting loralib\n  Downloading loralib-0.1.2-py3-none-any.whl.metadata (15 kB)\nRequirement already satisfied: torch==2.5.1 in /usr/local/lib/python3.10/dist-packages (from torchaudio) (2.5.1+cu121)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.5.1->torchaudio) (3.17.0)\nRequirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.5.1->torchaudio) (4.12.2)\nRequirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.5.1->torchaudio) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.5.1->torchaudio) (3.1.4)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.5.1->torchaudio) (2024.12.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch==2.5.1->torchaudio) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch==2.5.1->torchaudio) (1.3.0)\nRequirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.29.0)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.11.6)\nRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.21.0)\nRequirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\nRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.67.1)\nCollecting hyperpyyaml (from speechbrain)\n  Downloading HyperPyYAML-1.2.2-py3-none-any.whl.metadata (7.6 kB)\nRequirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from speechbrain) (1.4.2)\nRequirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from speechbrain) (1.13.1)\nRequirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from speechbrain) (0.2.0)\nRequirement already satisfied: lightning-utilities>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (0.12.0)\nRequirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (75.1.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (2.4.1)\nCollecting ruamel.yaml>=0.17.28 (from hyperpyyaml->speechbrain)\n  Downloading ruamel.yaml-0.18.10-py3-none-any.whl.metadata (23 kB)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2025.1.31)\nCollecting ruamel.yaml.clib>=0.2.7 (from ruamel.yaml>=0.17.28->hyperpyyaml->speechbrain)\n  Downloading ruamel.yaml.clib-0.2.12-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.7 kB)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.5.1->torchaudio) (3.0.2)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->transformers) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->transformers) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.17->transformers) (2024.2.0)\nDownloading speechbrain-1.0.2-py3-none-any.whl (824 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m824.8/824.8 kB\u001b[0m \u001b[31m34.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading pystoi-0.4.1-py2.py3-none-any.whl (8.2 kB)\nDownloading loralib-0.1.2-py3-none-any.whl (10 kB)\nDownloading HyperPyYAML-1.2.2-py3-none-any.whl (16 kB)\nDownloading ruamel.yaml-0.18.10-py3-none-any.whl (117 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.7/117.7 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading ruamel.yaml.clib-0.2.12-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (722 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m722.2/722.2 kB\u001b[0m \u001b[31m40.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hBuilding wheels for collected packages: pesq\n  Building wheel for pesq (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for pesq: filename=pesq-0.0.4-cp310-cp310-linux_x86_64.whl size=262946 sha256=4cc403533097fca6c8996cfaeef106774ecdb18710cc5c30855ad10b499f3ea0\n  Stored in directory: /root/.cache/pip/wheels/c5/4e/2c/251524370c0fdd659e99639a0fbd0ca5a782c3aafcd456b28d\nSuccessfully built pesq\nInstalling collected packages: pesq, ruamel.yaml.clib, loralib, ruamel.yaml, hyperpyyaml, speechbrain, pystoi\nSuccessfully installed hyperpyyaml-1.2.2 loralib-0.1.2 pesq-0.0.4 pystoi-0.4.1 ruamel.yaml-0.18.10 ruamel.yaml.clib-0.2.12 speechbrain-1.0.2\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"import os\nimport glob\nimport torch\nimport torchaudio\nimport numpy as np\nimport random\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom tqdm import tqdm\nfrom torch import nn\nfrom torch.optim import Adam\nfrom torch.utils.data import Dataset, DataLoader\nfrom transformers import (\n    Wav2Vec2ForSequenceClassification,\n    Wav2Vec2FeatureExtractor,\n    Wav2Vec2Model,\n    Trainer,\n    TrainingArguments\n)\nfrom speechbrain.pretrained import SepformerSeparation as SepFormer\nfrom torchmetrics.classification import BinaryAUROC, BinaryAccuracy\nfrom pesq import pesq\nfrom pystoi import stoi\nimport loralib as lora\nimport torch.nn.functional as F\n\n\n# Configuration\nclass Config:\n    # Dataset paths\n    VOX1_PATH = \"/kaggle/input/voxdataset/vox1/vox1/vox1_test_wav/wav\"\n    VOX2_AUDIO_PATH = \"/kaggle/input/voxdataset/vox2/vox2/vox2_test_aac/aac\"\n    VOX2_TXT_PATH = \"/kaggle/input/voxdataset/vox2/vox2/vox2_test_txt/txt\"\n    \n    # Model\n    MODEL_NAME = \"facebook/wav2vec2-large-xlsr-53\"\n    SEPFORMER_MODEL = \"speechbrain/sepformer-wsj02mix\"\n    \n    # Training\n    NUM_TRAIN_ID = 20 #4 #100\n    NUM_TEST_ID =   4 #2 #18\n    NUM_TRAIN_MIX_ID = 5 #2 # 50\n    NUM_TEST_MIX_ID =  5 #2 # 50\n    BATCH_SIZE = 10\n    LR = 1e-5\n    LORA_RANK = 8\n    NUM_EPOCHS = 3 #3\n    \n    # Evaluation\n    SAMPLE_RATE = 16000\n    METRICS = ['eer', 'tar@1%far', 'accuracy', 'sir', 'sar', 'sdr', 'pesq', 'stoi']\n    \n    # Resources\n    DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    MAX_AUDIO_LENGTH = 16000 * 5  # 5 seconds max\n\nconfig = Config()\n\ndef parse_speaker_metadata(txt_root_path):\n    speaker_metadata = {}\n    for speaker_id in os.listdir(txt_root_path):\n        speaker_path = os.path.join(txt_root_path, speaker_id)\n        if os.path.isdir(speaker_path):\n            for video_id in os.listdir(speaker_path):\n                video_path = os.path.join(speaker_path, video_id)\n                if os.path.isdir(video_path):\n                    # Map all files in this video directory to the speaker\n                    speaker_metadata[video_id] = speaker_id\n    return speaker_metadata\n\ndef generate_trial_pairs(audio_files, num_pairs=1000, same_speaker_ratio=0.5):\n    \"\"\"Generate synthetic trial pairs from audio files\"\"\"\n    # Organize files by speaker\n    speaker_files = {}\n    for file_path in audio_files:\n        parts = file_path.split('/')\n        if len(parts) >= 3:  # Ensure we have enough path components\n            speaker_id = parts[-3]  # Get speaker ID from path\n            if speaker_id not in speaker_files:\n                speaker_files[speaker_id] = []\n            speaker_files[speaker_id].append(file_path)\n    \n    # Check if we have enough speakers\n    if len(speaker_files) < 2:\n        raise ValueError(f\"Need at least 2 speakers, but only found {len(speaker_files)}\")\n    \n    # Generate pairs\n    pairs = []\n    speakers = list(speaker_files.keys())\n    \n    for _ in range(num_pairs):\n        if random.random() < same_speaker_ratio:\n            # Same speaker pair - ensure speaker has at least 2 files\n            valid_speakers = [s for s in speakers if len(speaker_files[s]) >= 2]\n            if not valid_speakers:\n                continue  # Skip if no speaker has multiple files\n                \n            speaker = random.choice(valid_speakers)\n            file1, file2 = random.sample(speaker_files[speaker], 2)\n            label = 1\n        else:\n            # Different speaker pair\n            if len(speakers) < 2:\n                continue  # Skip if not enough speakers\n                \n            speaker1, speaker2 = random.sample(speakers, 2)\n            file1 = random.choice(speaker_files[speaker1])\n            file2 = random.choice(speaker_files[speaker2])\n            label = 0\n        \n        pairs.append((file1, file2, label))\n    \n    # If we couldn't generate enough pairs, reduce the number\n    if len(pairs) < num_pairs:\n        print(f\"Warning: Only generated {len(pairs)} pairs (requested {num_pairs})\")\n    \n    return pairs\n\ndef organize_files_by_speaker(file_paths, speaker_metadata, num_speakers=None):\n    \"\"\"Organize files by speaker ID using the parsed metadata\"\"\"\n    speaker_files = {}\n    \n    for file_path in file_paths:\n        # Extract the video ID (directory name right before filename)\n        path_parts = file_path.split(os.sep)\n        video_id = path_parts[-2]  # Gets 'cQh9UMwhH1M' from '/.../cQh9UMwhH1M/00249.m4a'\n        \n        speaker_id = speaker_metadata.get(video_id)\n        if speaker_id:\n            if speaker_id not in speaker_files:\n                speaker_files[speaker_id] = []\n            speaker_files[speaker_id].append(file_path)\n\n    # Debug: Show speaker distribution\n    print(f\"Found {len(speaker_files)} speakers with files\")\n    for speaker, files in list(speaker_files.items())[:5]:\n        print(f\"Speaker {speaker} has {len(files)} files\")\n    \n    # Sort speakers and optionally limit number\n    sorted_speakers = sorted(speaker_files.keys())\n    if num_speakers:\n        sorted_speakers = sorted_speakers[:num_speakers]\n    \n    # Flatten file list in speaker order\n    organized_files = []\n    for speaker in sorted_speakers:\n        organized_files.extend(speaker_files[speaker])\n    \n    return organized_files\n\ndef collate_fn(batch):\n    \"\"\"Custom collate function to handle dictionary inputs\"\"\"\n    inputs1 = [item[0] for item in batch]\n    inputs2 = [item[1] for item in batch]\n    labels = torch.tensor([item[2] for item in batch])\n    \n    # Stack inputs properly\n    batch1 = {\n        'input_values': torch.cat([x['input_values'] for x in inputs1]),\n        'attention_mask': torch.cat([x['attention_mask'] for x in inputs1])\n    }\n    batch2 = {\n        'input_values': torch.cat([x['input_values'] for x in inputs2]),\n        'attention_mask': torch.cat([x['attention_mask'] for x in inputs2])\n    }\n    \n    return batch1, batch2, labels\n\nclass VoxCelebDataset(Dataset):\n    def __init__(self, file_paths, sample_rate=16000, max_length=16000*5):\n        self.file_paths = file_paths\n        self.sample_rate = sample_rate\n        self.max_length = max_length\n        \n    def __getitem__(self, idx):\n        try:\n            waveform, sr = torchaudio.load(self.file_paths[idx])\n            if waveform.shape[0] > 1:\n                waveform = torch.mean(waveform, dim=0, keepdim=True)\n                \n            if sr != self.sample_rate:\n                resampler = torchaudio.transforms.Resample(sr, self.sample_rate)\n                waveform = resampler(waveform)\n            \n            if waveform.shape[1] > self.max_length:\n                waveform = waveform[:, :self.max_length]\n            else:\n                pad_amount = self.max_length - waveform.shape[1]\n                waveform = torch.nn.functional.pad(waveform, (0, pad_amount))\n            \n            return waveform.squeeze(0).numpy()  # Return as 1D numpy array\n            \n        except Exception as e:\n            print(f\"Error loading {self.file_paths[idx]}: {e}\")\n            return np.zeros(self.max_length)\n            \n    def __len__(self):\n        return len(self.file_paths)\n            \nclass SpeakerVerificationDataset(Dataset):\n    \"\"\"Dataset for speaker verification using generated pairs\"\"\"\n    def __init__(self, root_dir, feature_extractor, num_pairs=100, max_length=16000*5):\n        self.root_dir = root_dir\n        self.feature_extractor = feature_extractor\n        self.max_length = max_length\n        self.audio_files = glob.glob(os.path.join(root_dir, \"**\", \"*.wav\"), recursive=True)\n        \n        if not self.audio_files:\n            raise ValueError(f\"No audio files found in {root_dir}\")\n            \n        self.trial_pairs = generate_trial_pairs(self.audio_files, num_pairs)\n        \n        if not self.trial_pairs:\n            raise ValueError(\"Could not generate any trial pairs - check your dataset structure\")\n        \n    def __len__(self):\n        return len(self.trial_pairs)\n    \n    def __getitem__(self, idx):\n        pair = self.trial_pairs[idx]\n        try:\n            # Load and process first audio\n            audio1, sr1 = torchaudio.load(pair[0])\n            audio1 = self._process_audio(audio1, sr1)\n            \n            # Load and process second audio\n            audio2, sr2 = torchaudio.load(pair[1])\n            audio2 = self._process_audio(audio2, sr2)\n            \n            # Extract features\n            inputs1 = self.feature_extractor(\n                audio1.numpy(), \n                return_tensors=\"pt\", \n                sampling_rate=config.SAMPLE_RATE,\n                padding=True\n            )\n            inputs2 = self.feature_extractor(\n                audio2.numpy(), \n                return_tensors=\"pt\", \n                sampling_rate=config.SAMPLE_RATE,\n                padding=True\n            )\n            \n            return inputs1, inputs2, pair[2]  # label\n            \n        except Exception as e:\n            print(f\"Error loading pair {pair}: {e}\")\n            # Return a random valid pair instead\n            return self[random.randint(0, len(self)-1)]\n    \n    def _process_audio(self, audio, sr):\n        \"\"\"Process audio to consistent length\"\"\"\n        # Resample if needed\n        if sr != config.SAMPLE_RATE:\n            resampler = torchaudio.transforms.Resample(sr, config.SAMPLE_RATE)\n            audio = resampler(audio)\n        \n        # Convert to mono if needed\n        if audio.shape[0] > 1:\n            audio = torch.mean(audio, dim=0, keepdim=True)\n        \n        # Trim or pad to max_length\n        if audio.shape[1] > self.max_length:\n            audio = audio[:, :self.max_length]\n        elif audio.shape[1] < self.max_length:\n            pad_amount = self.max_length - audio.shape[1]\n            audio = torch.nn.functional.pad(audio, (0, pad_amount))\n        \n        return audio.squeeze()\n\nclass MultiSpeakerDataset(Dataset):\n    def __init__(self, speaker_files, num_speakers=2, target_length=80000):\n        self.speaker_files = speaker_files\n        self.num_speakers = num_speakers\n        self.target_length = target_length\n        self.pairs = self._create_mixture_pairs()  # This will now work\n\n    def _create_mixture_pairs(self):\n        \"\"\"Create groups of audio files to mix together\"\"\"\n        # Ensure we have enough files to create mixtures\n        if len(self.speaker_files) < self.num_speakers:\n            raise ValueError(f\"Need at least {self.num_speakers} files but only have {len(self.speaker_files)}\")\n            \n        # Create sliding window of audio file groups\n        pairs = []\n        for i in range(len(self.speaker_files) - self.num_speakers + 1):\n            pairs.append(self.speaker_files[i:i+self.num_speakers])\n        return pairs\n\n    def __len__(self):\n        return len(self.pairs)\n\n    def __getitem__(self, idx):\n        audio_samples = []\n        for file in self.pairs[idx]:\n            audio, _ = torchaudio.load(file)\n            \n            # Trim or pad to target length\n            if audio.shape[1] > self.target_length:\n                audio = audio[:, :self.target_length]\n            else:\n                pad_amount = self.target_length - audio.shape[1]\n                audio = torch.nn.functional.pad(audio, (0, pad_amount))\n            \n            audio_samples.append(audio)\n        \n        # Mix speakers (now all have same length)\n        mixed = torch.mean(torch.stack(audio_samples), dim=0)\n        return mixed, audio_samples\n\nclass ArcFaceLoss(nn.Module):\n    \"\"\"Modified ArcFace loss that works with logits (instead of embeddings)\"\"\"\n    def __init__(self, num_classes, s=30.0, m=0.5):\n        super().__init__()\n        self.s = s\n        self.m = m\n        self.num_classes = num_classes\n        \n    def forward(self, logits, labels):\n        # Normalize logits (treat as pre-normalized embeddings)\n        logits = F.normalize(logits, p=2, dim=1)\n        \n        # Add angular margin\n        theta = torch.acos(torch.clamp(logits, -1.0 + 1e-7, 1.0 - 1e-7))\n        target_logits = torch.cos(theta + self.m)\n        one_hot = F.one_hot(labels, num_classes=self.num_classes).float()\n        one_hot = one_hot.to(logits.device)\n        \n        # Apply margin and scale\n        output = self.s * (one_hot * target_logits + (1 - one_hot) * logits)\n        return F.cross_entropy(output, labels)\n\n\nclass SpeakerVerificationModel(nn.Module):\n    \"\"\"Speaker verification model with LoRA adaptation\"\"\"\n    def __init__(self, model_name, num_classes, use_lora=True):\n        super().__init__()\n        # Load base model without classification head\n        self.base_model = Wav2Vec2Model.from_pretrained(model_name)\n        self.num_classes = num_classes\n        \n        # Get hidden size from config\n        hidden_size = self.base_model.config.hidden_size\n        \n        # Add projection layers\n        self.projection = nn.Sequential(\n            nn.Linear(hidden_size, hidden_size),\n            nn.ReLU(),\n            nn.Linear(hidden_size, num_classes))\n        \n        # Apply LoRA to attention layers\n        if use_lora:\n            for layer in self.base_model.encoder.layers:\n                layer.attention.q_proj = lora.Linear(\n                    layer.attention.q_proj.in_features,\n                    layer.attention.q_proj.out_features,\n                    r=config.LORA_RANK)\n                # [Repeat for k_proj, v_proj, out_proj as in your original code]\n                \n                # Freeze original parameters\n                for param in layer.parameters():\n                    param.requires_grad = False\n                # Unfreeze LoRA parameters\n                for param in layer.attention.q_proj.parameters():\n                    param.requires_grad = True\n                # [Repeat for other projections]\n        \n    def forward(self, input_values, attention_mask=None):\n        outputs = self.base_model(\n            input_values,\n            attention_mask=attention_mask,\n            output_hidden_states=True)\n        \n        # Use last hidden state\n        hidden_states = outputs.last_hidden_state\n        \n        # Mean pooling\n        if attention_mask is not None:\n            input_lengths = attention_mask.sum(-1)\n            pooled_output = hidden_states.sum(dim=1) / input_lengths.unsqueeze(-1)\n        else:\n            pooled_output = hidden_states.mean(dim=1)\n        \n        return self.projection(pooled_output)\n        \nclass SpeakerVerificationEvaluator:\n    \"\"\"Evaluator for speaker verification tasks\"\"\"\n    def __init__(self, model, feature_extractor):\n        self.model = model\n        self.feature_extractor = feature_extractor\n        self.auroc = BinaryAUROC()\n        self.accuracy = BinaryAccuracy()\n        \n    def evaluate(self, dataloader):\n        self.model.eval()\n        scores, labels = [], []\n        \n        with torch.no_grad():\n            for inputs1, inputs2, label in tqdm(dataloader, desc=\"Evaluating\"):\n                # Move inputs to device\n                inputs1 = {k: v.to(config.DEVICE) for k, v in inputs1.items()}\n                inputs2 = {k: v.to(config.DEVICE) for k, v in inputs2.items()}\n          \n                # Forward pass - now directly getting embeddings\n                emb1 = self.model(**inputs1)\n                emb2 = self.model(**inputs2)\n              \n                # Calculate similarity score (cosine similarity of embeddings)\n                score = F.cosine_similarity(emb1, emb2, dim=1)\n                \n                scores.extend(score.cpu().tolist())\n                labels.extend(label.cpu().tolist())\n        \n        # Calculate metrics\n        scores = torch.tensor(scores)\n        labels = torch.tensor(labels)\n        \n        auroc_score = self.auroc(scores, labels)\n        acc_score = self.accuracy((scores > 0.5).float(), labels)\n        \n        # Calculate EER\n        eer = self._calculate_eer(scores, labels)\n        \n        return {\n            'eer': eer,\n            'auroc': auroc_score.item(),\n            'accuracy': acc_score.item(),\n            'tar@1%far': self._calculate_tar_at_far(scores, labels, 0.01)\n        }\n    \n    def _calculate_eer(self, scores, labels):\n        # Sort scores with corresponding labels\n        sorted_indices = torch.argsort(scores)\n        sorted_labels = labels[sorted_indices]\n        \n        # Calculate FAR and FRR\n        far = []\n        frr = []\n        thresholds = scores[sorted_indices]\n        \n        for threshold in thresholds:\n            far.append(((scores >= threshold) & (labels == 0)).float().mean())\n            frr.append(((scores < threshold) & (labels == 1)).float().mean())\n        \n        # Find point where FAR and FRR are closest\n        diff = torch.abs(torch.tensor(far) - torch.tensor(frr))\n        eer_idx = torch.argmin(diff)\n        return far[eer_idx].item()\n    \n    def _calculate_tar_at_far(self, scores, labels, target_far):\n        # Sort scores with corresponding labels\n        sorted_indices = torch.argsort(scores)\n        sorted_scores = scores[sorted_indices]\n        sorted_labels = labels[sorted_indices]\n\n        # Initialize threshold with most conservative value (accept none)\n        threshold = sorted_scores[-1] + 1  # Will accept nothing\n        \n        # Find threshold that gives target FAR\n        for i in range(len(sorted_scores)):\n            far = ((sorted_scores >= sorted_scores[i]) & (sorted_labels == 0)).float().mean()\n            if far <= target_far:\n                threshold = sorted_scores[i]\n                break\n        \n        # Calculate TAR at this threshold\n        tar = ((sorted_scores >= threshold) & (sorted_labels == 1)).float().mean()\n        return tar.item()\n\nclass SeparationEvaluator:\n    \"\"\"Evaluator for speaker separation tasks\"\"\"\n    def __init__(self, sample_rate=16000):\n        self.sample_rate = sample_rate\n        \n    def evaluate(self, original, separated, mixed):\n        metrics = {}\n        \n        # Convert all inputs to numpy arrays first\n        original = self._ensure_numpy(original)\n        separated = self._ensure_numpy(separated)\n        mixed = self._ensure_numpy(mixed)\n        \n        # Handle multi-channel separated audio\n        if separated.ndim > 1:\n            separated = separated[:,0] if separated.shape[1] > 1 else separated.squeeze()\n        \n        # Calculate metrics\n        metrics.update(self._calculate_bss_metrics(original, separated, mixed))\n        metrics['pesq'] = pesq(self.sample_rate, original, separated, 'wb')\n        metrics['stoi'] = stoi(original, separated, self.sample_rate)\n        \n        return metrics\n    \n    def _ensure_numpy(self, x):\n        \"\"\"Convert input to numpy array, handling both torch tensors and numpy arrays\"\"\"\n        if hasattr(x, 'numpy'):  # Torch tensor\n            return x.squeeze().cpu().numpy()\n        return np.asarray(x).squeeze()  # Numpy array or similar\n    \n    def _calculate_bss_metrics(self, original, separated, mixed):\n        \"\"\"Inputs are guaranteed to be numpy arrays at this point\"\"\"\n        sdr = 10 * np.log10(np.sum(original**2) / np.sum((original - separated)**2))\n        sir = 10 * np.log10(np.sum(original**2) / np.sum((mixed - separated)**2))\n        sar = 10 * np.log10(np.sum(separated**2) / np.sum((separated - original)**2))\n        \n        return {\n            'sdr': sdr,\n            'sir': sir,\n            'sar': sar\n        }\n\nclass SpeakerSeparationPipeline:\n    def __init__(self, sepformer_model, verification_model, feature_extractor):\n        self.sepformer = sepformer_model\n        self.verification_model = verification_model\n        self.feature_extractor = feature_extractor\n        self.min_audio_length = 400  # Minimum samples needed for Wav2Vec2 (400 = 25ms at 16kHz)\n        \n    def separate_and_identify(self, mixed_audio):\n        # Separate speakers\n        separated = self.sepformer.separate_batch(mixed_audio)\n        \n        # Identify each separated speaker\n        identifications = []\n        for speaker_audio in separated:\n            # Skip empty/invalid outputs\n            if speaker_audio.numel() == 0 or speaker_audio.shape[-1] < self.min_audio_length:\n                identifications.append(-1)  # Mark as invalid\n                continue\n                \n            # Process valid audio\n            inputs = self.feature_extractor(\n                speaker_audio.squeeze().cpu().numpy(),\n                return_tensors=\"pt\",\n                sampling_rate=config.SAMPLE_RATE,\n                padding=\"max_length\",  # Ensure fixed length\n                max_length=max(speaker_audio.shape[-1], self.min_audio_length)\n            ).to(config.DEVICE)\n            \n            with torch.no_grad():\n                outputs = self.verification_model(**inputs)\n                identifications.append(outputs.logits.argmax().item())\n        \n        return separated, identifications\n\ndef audio_collate_fn(batch):\n    # Convert list of numpy arrays to tensors and stack\n    return torch.stack([torch.from_numpy(x) for x in batch])\n\ndef verification_collate_fn(batch):\n    inputs1 = []\n    inputs2 = []\n    labels = []\n    \n    for item in batch:\n        feat1, feat2, label = item\n        \n        # Ensure proper shapes\n        if feat1['input_values'].dim() == 1:\n            feat1['input_values'] = feat1['input_values'].unsqueeze(0)\n        if feat2['input_values'].dim() == 1:\n            feat2['input_values'] = feat2['input_values'].unsqueeze(0)\n            \n        inputs1.append(feat1)\n        inputs2.append(feat2)\n        labels.append(label)\n    \n    batch1 = {\n        'input_values': torch.cat([x['input_values'] for x in inputs1]),\n        'attention_mask': torch.cat([x['attention_mask'] for x in inputs1])\n    }\n    batch2 = {\n        'input_values': torch.cat([x['input_values'] for x in inputs2]),\n        'attention_mask': torch.cat([x['attention_mask'] for x in inputs2])\n    }\n    \n    return batch1, batch2, torch.tensor(labels)\n\ndef plot_results(pre_train, post_train, separation):\n    \"\"\"Visualize results\"\"\"\n    # Verification metrics\n    verif_metrics = ['eer', 'accuracy', 'tar@1%far']\n    pre_values = [pre_train[m] for m in verif_metrics]\n    post_values = [post_train[m] for m in verif_metrics]\n    \n    x = np.arange(len(verif_metrics))\n    width = 0.35\n    \n    fig, ax = plt.subplots(figsize=(10, 6))\n    ax.bar(x - width/2, pre_values, width, label='Pre-training')\n    ax.bar(x + width/2, post_values, width, label='Post-training')\n    \n    ax.set_ylabel('Score')\n    ax.set_title('Verification Metrics Comparison')\n    ax.set_xticks(x)\n    ax.set_xticklabels(verif_metrics)\n    ax.legend()\n    plt.show()\n    \n    # Separation metrics\n    sep_metrics = ['sdr', 'sir', 'sar', 'pesq', 'stoi']\n    sep_values = [separation[m] for m in sep_metrics]\n    \n    fig, ax = plt.subplots(figsize=(10, 6))\n    ax.bar(sep_metrics, sep_values)\n    ax.set_ylabel('Score')\n    ax.set_title('Separation Metrics')\n    plt.show()\n\ndef main():\n    # Initialize models\n    feature_extractor = Wav2Vec2FeatureExtractor.from_pretrained(config.MODEL_NAME)\n    verification_model = SpeakerVerificationModel(config.MODEL_NAME, config.NUM_TRAIN_ID).to(config.DEVICE)\n    sepformer = SepFormer.from_hparams(\n        source=config.SEPFORMER_MODEL,\n        savedir=\"sepformer\",\n        run_opts={\"device\": config.DEVICE}\n    )\n    \n    # Load and organize data\n    print(\"Loading and organizing data...\")\n    \n    # Load VoxCeleb2 files and metadata\n    print(\"Loading and organizing data...\")\n    vox2_files = glob.glob(os.path.join(config.VOX2_AUDIO_PATH, \"**\", \"*.m4a\"), recursive=True)\n    print(f\"Found {len(vox2_files)} raw audio files\")\n    \n    speaker_metadata = parse_speaker_metadata(config.VOX2_TXT_PATH)\n    print(f\"Sample metadata: {dict(list(speaker_metadata.items())[:3])}\")\n\n    # Verify first few files\n    for i in range(3):\n        file_path = vox2_files[i]\n        video_id = file_path.split(os.sep)[-2]\n        print(f\"\\nFile {i+1}: {file_path}\")\n        print(f\"Extracted video ID: {video_id}\")\n        print(f\"Mapped to speaker: {speaker_metadata.get(video_id)}\")\n\n    print(\"Sample metadata entries:\", dict(list(speaker_metadata.items())[:5]))\n    print(\"Sample audio files:\", vox2_files[:5])\n    \n    # Organize VoxCeleb2 by speaker\n    print(f\"Found {len(vox2_files)} raw audio files\")\n    \n    train_files = organize_files_by_speaker(\n        vox2_files, speaker_metadata, config.NUM_TRAIN_ID\n    )\n    print(f\"Organized {len(train_files)} training files\")\n\n    test_files = organize_files_by_speaker(\n        vox2_files, speaker_metadata, config.NUM_TRAIN_ID + config.NUM_TEST_ID\n    )[config.NUM_TRAIN_ID:]\n\n    print(f\"\\nOrganized {len(train_files)} training files from {len(speaker_metadata)} speakers\")\n    \n    if not train_files:\n        print(\"\\nDEBUG: Failed to organize files. Checking structure...\")\n        print(\"Sample audio path:\", vox2_files[0])\n        print(\"Sample metadata keys:\", list(speaker_metadata.keys())[:5])\n        return\n    \n    # Create verification dataset with synthetic pairs\n    verif_dataset = SpeakerVerificationDataset(config.VOX1_PATH, feature_extractor)\n    verif_dataloader = DataLoader(\n        verif_dataset, \n        batch_size=config.BATCH_SIZE,\n        collate_fn=collate_fn\n    )\n    \n    # Create multi-speaker datasets\n    print(f\"Found {len(vox2_files)} raw audio files\")\n    \n    train_mix_files = organize_files_by_speaker(\n        vox2_files, speaker_metadata, config.NUM_TRAIN_MIX_ID\n    )\n\n    print(f\"Organized {len(train_files)} training files\")\n\n    test_mix_files = organize_files_by_speaker(\n        vox2_files, speaker_metadata, config.NUM_TRAIN_MIX_ID + config.NUM_TEST_MIX_ID\n    )[config.NUM_TRAIN_MIX_ID:]\n    \n    train_mix_dataset = MultiSpeakerDataset(\n        train_mix_files,target_length=config.MAX_AUDIO_LENGTH)\n    test_mix_dataset = MultiSpeakerDataset( test_mix_files,target_length=config.MAX_AUDIO_LENGTH )\n    \n    # Initialize evaluators\n    verif_evaluator = SpeakerVerificationEvaluator(verification_model, feature_extractor)\n    sep_evaluator = SeparationEvaluator(sample_rate=config.SAMPLE_RATE)\n    \n    # Pre-training evaluation\n    print(\"Pre-training evaluation...\")\n    pre_train_metrics = verif_evaluator.evaluate(verif_dataloader)\n    print(\"Pre-training metrics:\", pre_train_metrics)\n    \n    # Fine-tune with LoRA and ArcFace\n    print(\"Fine-tuning model...\")\n    optimizer = Adam(verification_model.parameters(), lr=config.LR)\n    #loss_fn = ArcFaceLoss(config.NUM_TRAIN_ID, verification_model.base_model.config.hidden_size)\n    loss_fn = ArcFaceLoss(config.NUM_TRAIN_ID)\n\n    # Create training dataset and dataloader\n    \n    \n    if len(train_files) == 0:\n        raise ValueError(\"No training files found! Check your data paths and organization\")\n\n    train_dataset = VoxCelebDataset(\n        train_files,\n        sample_rate=config.SAMPLE_RATE,\n        max_length=config.MAX_AUDIO_LENGTH\n    )\n\n    train_dataloader = DataLoader(\n        VoxCelebDataset(train_files),\n        batch_size=config.BATCH_SIZE,\n        shuffle=True,\n        collate_fn=audio_collate_fn\n    )\n\n    verif_dataloader = DataLoader(\n    SpeakerVerificationDataset(config.VOX1_PATH, feature_extractor),\n    batch_size=config.BATCH_SIZE,\n    collate_fn=verification_collate_fn\n    )\n    \n    verification_model.train()\n\n    # Print dataset properties\n    print(f\"Training dataset size: {len(train_dataset)}\")\n    print(f\"Test dataset size: {len(test_mix_dataset)}\")\n    \n    # Print training settings\n    print(f\"Batch size: {config.BATCH_SIZE}\")\n    print(f\"Learning rate: {config.LR}\")\n    print(f\"Number of epochs: {config.NUM_EPOCHS}\")\n    \n    # Print verification dataset size\n    print(f\"Verification dataset size: {len(verif_dataset)}\")\n    \n# Replace the training loop with:\n    for epoch in range(config.NUM_EPOCHS):\n        epoch_loss = 0\n        for audio_batch in tqdm(train_dataloader, desc=f\"Epoch {epoch+1}/{config.NUM_EPOCHS}\"):\n            # Feature extraction\n            inputs = feature_extractor(\n                [x.numpy() for x in audio_batch],  # Convert to list of numpy arrays\n                return_tensors=\"pt\",\n                sampling_rate=config.SAMPLE_RATE,\n                padding=True\n            ).to(config.DEVICE)\n            \n            # Training step\n            labels = torch.arange(len(audio_batch)).to(config.DEVICE)\n            #labels = torch.arange(len(audio_batch)).to(config.DEVICE) % num_classes\n            optimizer.zero_grad()\n            outputs = verification_model(**inputs)\n            loss = loss_fn(outputs, labels)\n            loss.backward()\n            optimizer.step()\n            \n    print(f\"Epoch {epoch+1} Loss: {epoch_loss / len(train_dataloader)}\")\n\n\n\n    # Post-training evaluation\n    print(\"Post-training evaluation...\")\n    post_train_metrics = verif_evaluator.evaluate(verif_dataloader)\n    print(\"Post-training metrics:\", post_train_metrics)\n    \n    # Speaker separation and identification\n    print(\"Running separation and identification...\")\n    pipeline = SpeakerSeparationPipeline(sepformer, verification_model, feature_extractor)\n    \n    # Evaluate on test mixtures\n    test_results = []\n    for mixed, originals in tqdm(test_mix_dataset, desc=\"Processing test mixtures\"):\n        mixed = mixed.to(config.DEVICE)\n        separated, ids = pipeline.separate_and_identify(mixed)\n        \n        # Evaluate separation quality for each speaker\n        for orig, sep in zip(originals, separated):\n            metrics = sep_evaluator.evaluate(orig, sep, mixed)\n            test_results.append(metrics)\n    \n    # Calculate average metrics\n    avg_metrics = {metric: np.mean([r[metric] for r in test_results]) for metric in config.METRICS if metric in test_results[0]}\n    print(\"Average separation metrics:\", avg_metrics)\n\n    # Print final separation results\n    print(f\"Total test mixtures processed: {len(test_mix_dataset)}\")\n    print(f\"Final computed metrics: {avg_metrics}\")\n\n    # Visualization\n    plot_results(pre_train_metrics, post_train_metrics, avg_metrics)\n\nif __name__ == \"__main__\":\n    main()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-30T14:43:11.429167Z","iopub.execute_input":"2025-03-30T14:43:11.429490Z","iopub.status.idle":"2025-03-30T15:39:45.614975Z","shell.execute_reply.started":"2025-03-30T14:43:11.429462Z","shell.execute_reply":"2025-03-30T15:39:45.614196Z"}},"outputs":[{"name":"stderr","text":"<ipython-input-3-4ff958e5139d>:21: UserWarning: Module 'speechbrain.pretrained' was deprecated, redirecting to 'speechbrain.inference'. Please update your script. This is a change from SpeechBrain 1.0. See: https://github.com/speechbrain/speechbrain/releases/tag/v1.0.0\n  from speechbrain.pretrained import SepformerSeparation as SepFormer\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"preprocessor_config.json:   0%|          | 0.00/212 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"66bd9173b43747d3b054b45a5b33f32f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.77k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0a8f45efad2b431eaa35add8dc40dbb8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/1.27G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"802d1dfdbc7b4630b506b2c5cd4dba6a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"hyperparams.yaml:   0%|          | 0.00/1.51k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1e253f2654c34820af006b3bdc05adad"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"masknet.ckpt:   0%|          | 0.00/113M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0b3ada8a6439484eaaad8c875ded9986"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"encoder.ckpt:   0%|          | 0.00/17.3k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6faf801f7d1243249175106b7af4b0f2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"decoder.ckpt:   0%|          | 0.00/17.2k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b3fe4ff227c04e569b8236e7d35eea0f"}},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/speechbrain/utils/checkpoints.py:200: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  state_dict = torch.load(path, map_location=device)\n","output_type":"stream"},{"name":"stdout","text":"Loading and organizing data...\nLoading and organizing data...\nFound 36237 raw audio files\nSample metadata: {'cQh9UMwhH1M': 'id08456', 'EhW1yHW9fvA': 'id08456', '57jM1IfuGag': 'id08456'}\n\nFile 1: /kaggle/input/voxdataset/vox2/vox2/vox2_test_aac/aac/id08456/cQh9UMwhH1M/00249.m4a\nExtracted video ID: cQh9UMwhH1M\nMapped to speaker: id08456\n\nFile 2: /kaggle/input/voxdataset/vox2/vox2/vox2_test_aac/aac/id08456/cQh9UMwhH1M/00247.m4a\nExtracted video ID: cQh9UMwhH1M\nMapped to speaker: id08456\n\nFile 3: /kaggle/input/voxdataset/vox2/vox2/vox2_test_aac/aac/id08456/cQh9UMwhH1M/00248.m4a\nExtracted video ID: cQh9UMwhH1M\nMapped to speaker: id08456\nSample metadata entries: {'cQh9UMwhH1M': 'id08456', 'EhW1yHW9fvA': 'id08456', '57jM1IfuGag': 'id08456', 'DZuVAGI6Lj4': 'id08456', 'oIbTvcLvW8w': 'id08456'}\nSample audio files: ['/kaggle/input/voxdataset/vox2/vox2/vox2_test_aac/aac/id08456/cQh9UMwhH1M/00249.m4a', '/kaggle/input/voxdataset/vox2/vox2/vox2_test_aac/aac/id08456/cQh9UMwhH1M/00247.m4a', '/kaggle/input/voxdataset/vox2/vox2/vox2_test_aac/aac/id08456/cQh9UMwhH1M/00248.m4a', '/kaggle/input/voxdataset/vox2/vox2/vox2_test_aac/aac/id08456/EhW1yHW9fvA/00099.m4a', '/kaggle/input/voxdataset/vox2/vox2/vox2_test_aac/aac/id08456/EhW1yHW9fvA/00097.m4a']\nFound 36237 raw audio files\nFound 118 speakers with files\nSpeaker id08456 has 425 files\nSpeaker id01892 has 128 files\nSpeaker id01567 has 500 files\nSpeaker id00061 has 288 files\nSpeaker id04119 has 83 files\nOrganized 6625 training files\nFound 118 speakers with files\nSpeaker id08456 has 425 files\nSpeaker id01892 has 128 files\nSpeaker id01567 has 500 files\nSpeaker id00061 has 288 files\nSpeaker id04119 has 83 files\n\nOrganized 6625 training files from 4910 speakers\nFound 36237 raw audio files\nFound 118 speakers with files\nSpeaker id08456 has 425 files\nSpeaker id01892 has 128 files\nSpeaker id01567 has 500 files\nSpeaker id00061 has 288 files\nSpeaker id04119 has 83 files\nOrganized 6625 training files\nFound 118 speakers with files\nSpeaker id08456 has 425 files\nSpeaker id01892 has 128 files\nSpeaker id01567 has 500 files\nSpeaker id00061 has 288 files\nSpeaker id04119 has 83 files\nPre-training evaluation...\n","output_type":"stream"},{"name":"stderr","text":"Evaluating: 100%|██████████| 10/10 [00:11<00:00,  1.11s/it]\n","output_type":"stream"},{"name":"stdout","text":"Pre-training metrics: {'eer': 0.3100000023841858, 'auroc': 0.4967987537384033, 'accuracy': 0.49000000953674316, 'tar@1%far': 0.0}\nFine-tuning model...\nTraining dataset size: 6625\nTest dataset size: 3005\nBatch size: 10\nLearning rate: 1e-05\nNumber of epochs: 3\nVerification dataset size: 100\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1/3: 100%|██████████| 663/663 [08:36<00:00,  1.28it/s]\nEpoch 2/3: 100%|██████████| 663/663 [08:33<00:00,  1.29it/s]\nEpoch 3/3: 100%|██████████| 663/663 [08:33<00:00,  1.29it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 3 Loss: 0.0\nPost-training evaluation...\n","output_type":"stream"},{"name":"stderr","text":"Evaluating: 100%|██████████| 10/10 [00:10<00:00,  1.08s/it]\n","output_type":"stream"},{"name":"stdout","text":"Post-training metrics: {'eer': 0.25999999046325684, 'auroc': 0.4276767373085022, 'accuracy': 0.44999998807907104, 'tar@1%far': 0.0}\nRunning separation and identification...\n","output_type":"stream"},{"name":"stderr","text":"Processing test mixtures: 100%|██████████| 3005/3005 [29:04<00:00,  1.72it/s]\n","output_type":"stream"},{"name":"stdout","text":"Average separation metrics: {'sir': -20.070502545393246, 'sar': -0.606255985017234, 'sdr': -20.09340985126781, 'pesq': 1.1588857117984537, 'stoi': 0.5632767171311212}\nTotal test mixtures processed: 3005\nFinal computed metrics: {'sir': -20.070502545393246, 'sar': -0.606255985017234, 'sdr': -20.09340985126781, 'pesq': 1.1588857117984537, 'stoi': 0.5632767171311212}\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 1000x600 with 1 Axes>","image/png":"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\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 1000x600 with 1 Axes>","image/png":"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\n"},"metadata":{}}],"execution_count":3},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}